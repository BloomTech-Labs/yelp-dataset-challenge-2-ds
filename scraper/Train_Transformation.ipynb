{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Transformation\n",
    "\n",
    "The tidy data collected during scrapes needs to be widened (one-hot encoded or embedded) prior to training.  FastMap can then pin a model with a X_transformed for future predictions.\n",
    "\n",
    "NOTE:  The perceptron isn't behaving well with this dataset.  Moving to sklearn's logistic regression for a bit more stability and pipeline constructs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from db import get_session\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter relevant data (within square boundary)\n",
    "\n",
    "Given a model centroid, get data within given radius.  For earlier versions, this can be done as a square, but future methods may require redesigning query filter statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_near_data(center_coord, radius):\n",
    "    lat_range = [center_coord[0]-radius, center_coord[0]+radius]\n",
    "    lon_range = [center_coord[1]-radius, center_coord[1]+radius]\n",
    "    \n",
    "    with get_session() as session:\n",
    "        response = session.query(\n",
    "            SearchResults.latitude, SearchResults.longitude,\n",
    "            SearchResults.category, SearchResults.num_unique).\\\n",
    "                filter(\n",
    "                    SearchResults.latitude > lat_range[0],\n",
    "                    SearchResults.latitude < lat_range[1],\n",
    "                    SearchResults.longitude > lon_range[0],\n",
    "                    SearchResults.longitude < lon_range[1]).all()\n",
    "    return response\n",
    "\n",
    "data = get_near_data((32.715736, -117.161087), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>cat</th>\n",
       "      <th>num_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.915736</td>\n",
       "      <td>-117.411087</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.915736</td>\n",
       "      <td>-117.411087</td>\n",
       "      <td>localservices</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.915736</td>\n",
       "      <td>-117.411087</td>\n",
       "      <td>physicians</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.915736</td>\n",
       "      <td>-117.411087</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.915736</td>\n",
       "      <td>-117.411087</td>\n",
       "      <td>realestate</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon            cat  num_unique\n",
       "0  32.915736 -117.411087           auto          50\n",
       "1  32.915736 -117.411087  localservices          50\n",
       "2  32.915736 -117.411087     physicians          50\n",
       "3  32.915736 -117.411087    restaurants          50\n",
       "4  32.915736 -117.411087     realestate          50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data into dataframe for encoding\n",
    "columns = ['lat', 'lon', 'cat', 'num_unique']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding is probably not ideal.  Categories change.  Looking at a simple word embedding for the category is likely a far more robust solution in the event categories are introduced that don't meet existing.  Then the one-hot isn't needed, just the expansion of a the vector list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick example with get_dummies.  Not suitable for final use.\n",
    "X = pd.get_dummies(df, columns=['cat']).drop(columns='num_unique').to_numpy()\n",
    "y = df.num_unique.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3      [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4      [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "                             ...                        \n",
       "368    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "369    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "370    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "371    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "372    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "Name: cat, Length: 373, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO IT MANUALLY CUZ F' SCIKIT LEARN\n",
    "from  read_query import list_categories\n",
    "from app_global import g\n",
    "\n",
    "def get_categories():\n",
    "    if not hasattr(g, 'categories'):    \n",
    "        g.categories = list_categories(with_id=True)\n",
    "    return g.categories\n",
    "\n",
    "def encode_cat(x):\n",
    "    categories = get_categories()\n",
    "    temp_arr = np.zeros(len(categories.keys()))\n",
    "    temp_arr[categories[x]-1] = 1\n",
    "    return temp_arr\n",
    "\n",
    "## Try to create binary vector for each row.\n",
    "df.cat.apply(encode_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  32.915736, -117.411087,    1.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_observation(obs):\n",
    "    assert len(obs) == 3\n",
    "    return np.concatenate(\n",
    "        (\n",
    "            [obs[0]], [obs[1]], encode_cat(obs[2])\n",
    "        ),\n",
    "        axis=None\n",
    "    )\n",
    "\n",
    "def truncate_x(obs):\n",
    "    return obs[0:3]\n",
    "\n",
    "def truncate_y(obs):\n",
    "    return obs[-1]\n",
    "\n",
    "\n",
    "transform_observation(truncate_x(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_transform(data):\n",
    "    # The perceptron is sigmoid activated.  y needs to be scaled to 0:1.\n",
    "    X_raw = list(map(\n",
    "            truncate_x, data\n",
    "        ))\n",
    "    X = np.array(list(map(\n",
    "            transform_observation, X_raw\n",
    "        )), dtype='f')\n",
    "    y = np.array(list(map(\n",
    "            truncate_y, data\n",
    "        )), dtype='f').reshape(-1,1)\n",
    "    return X, y/50.\n",
    "\n",
    "X, y = split_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  32.915737, -117.41109 ,    1.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ,\n",
       "          0.      ,    0.      ,    0.      ,    0.      ,    0.      ],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boom.  Hand implemented one-hot encoding with X, y split that will totally drop data\n",
    "#    if input is > 4 and throw a key error if category added to db during run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pin model with data\n",
    "\n",
    "Using X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 65)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(373, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize  modelmap\n",
    "modelmap = lens.ModelMap(\n",
    "    center_coord = [32.715736, -117.161087]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (373,373) and (1,10) not aligned: 373 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-dc5b9fc14ad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcoordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m32.715736\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m117.161087\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bin/yelp-dataset-challenge-2-ds/scraper/lens/fastmap.py\u001b[0m in \u001b[0;36mpin_model\u001b[0;34m(self, X, y, coordinates)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mgeohash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mfile_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_to_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeohash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeohash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeohash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bin/yelp-dataset-challenge-2-ds/scraper/lens/fastmap.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(model, X, y, num_epochs, coordinates)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bin/yelp-dataset-challenge-2-ds/scraper/lens/perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, learning_rate, epochs, verbose)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mnet_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bin/yelp-dataset-challenge-2-ds/scraper/lens/perceptron.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, X, y, net_output, learning_rate)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoidPrime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# Apply Derivative of Sigmoid to error (adjust based on slope of activation function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoidPrime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivated_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (373,373) and (1,10) not aligned: 373 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Pin model\n",
    "model_info = modelmap.pin_model(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    coordinates = [32.715736, -117.161087]\n",
    ")\n",
    "model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model data to database for later use\n",
    "\n",
    "The database will maintain a list of available perceptrons.  \n",
    "\n",
    "Note: Currently, these are stored in a temporary folder and so the database references are not valid after garbage collection or system restarts.  This table data will have to be dropped at the start of a run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from write_query import write_model_metadata\n",
    "\n",
    "write_model_metadata(model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Cache for Model Perseverence in Memory\n",
    "\n",
    "The cache should be keeping a number of the most recent or most used models for quick access.  This way it does not have to be loaded from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1577501386.5982246: {'model': <lens.perceptron.Perceptron at 0x7f7d2ef69490>,\n",
       "  'geohash': '9mudjgtyuz1w'}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelmap.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datapoint X for prediction of num_unique\n",
    "\n",
    "Input X_i must match the format of X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_input(x: tuple):\n",
    "    return np.array(x).reshape(1, -1)\n",
    "\n",
    "X_test, y = split_transform(prep_input(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  X is always the first out.  Though slightly inefficient, no logic is particulary needed to NOT return y.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually from cache\n",
    "model = modelmap.cache[list(modelmap.cache.keys())[0]]['model']\n",
    "# a lot to get the first item haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)*50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Pipeline Construction\n",
    "\n",
    "The single perceptron did not yield good resuslts, yielding effective averages instead of the learning desired.  This could be due to sparsity of the training set or fickle training hyperparameters.  \n",
    "\n",
    "Because of this, and the development of the input/training set tranformation functions, a move toward logistic regression will be tried.  Another thing gained by moving to Scikit-Learn's is pipeline functionality out of the box and access to a number of scaling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32.915736, -117.411087, 'auto', 50),\n",
       " (32.915736, -117.411087, 'localservices', 50),\n",
       " (32.915736, -117.411087, 'physicians', 50),\n",
       " (32.915736, -117.411087, 'restaurants', 50),\n",
       " (32.915736, -117.411087, 'realestate', 50),\n",
       " (32.915736, -117.411087, 'farms', 14),\n",
       " (32.915736, -117.411087, 'active', 49),\n",
       " (32.915736, -117.411087, 'partyequipmentrentals', 50),\n",
       " (32.915736, -117.411087, 'plumbing', 50),\n",
       " (32.915736, -117.411087, 'eventservices', 43)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Training Data around: \n",
    "from read_query import get_near_data\n",
    "\n",
    "test_center = [32.715736, -117.161087]\n",
    "data = get_near_data(center_coord=test_center, radius=0.5)\n",
    "data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lens\n",
    "\n",
    "X, y = lens.split_widen_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "lregr = LogisticRegression(\n",
    "    random_state=420,\n",
    "    solver='liblinear',\n",
    ")\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "tpipe = Pipeline([\n",
    "    ('scaler', standard_scaler),\n",
    "    ('logistic', lregr),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('logistic',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=420,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual: 38.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([12.], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = 65\n",
    "test_data = X[num]\n",
    "display(\n",
    "    tpipe.predict(test_data.reshape(1,-1)),\n",
    "    print('actual:', y[num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geohash': '9mudjgtyuz1w',\n",
       " 'latitude': 32.715736,\n",
       " 'longitude': -117.161087,\n",
       " 'radius': 0.05,\n",
       " 'observations': 373,\n",
       " 'file_location': '/tmp/9mudjgtyuz1w.pkl'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempt to pin pipeline model\n",
    "from lens import ModelMap\n",
    "\n",
    "# Initialize  modelmap\n",
    "modelmap = lens.ModelMap(\n",
    "    center_coord = [32.715736, -117.161087]\n",
    ")\n",
    "# Pin model\n",
    "model_info = modelmap.pin_model(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    coordinates = [32.715736, -117.161087]\n",
    ")\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually from cache\n",
    "model = modelmap.cache[list(modelmap.cache.keys())[0]]['model']\n",
    "model.predict(X[65].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
